{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from model import db_connect,create_table\n",
    "from bs4 import Tag\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as req\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from img_scraper.model import db_connect,create_table\n",
    "\n",
    "def grap_preview_imgs_urls(img_table, engine):\n",
    "    '''\n",
    "    get img - url pair from the model\n",
    "    db_img_http: column name from the model,such as preview_img_link/title_img_url\n",
    "    db_img_local:column name from the mode, such as preview_img_local/title_img_local\n",
    "    '''\n",
    "    ori_df = pd.read_sql_table(img_table, engine)\n",
    "    preview_imgs_urls = {}\n",
    "    for row in ori_df.itertuples():\n",
    "        #         print(dir(row))\n",
    "        img_url = {}\n",
    "        prview_img_links = []\n",
    "        preview_img_locals = []\n",
    "        prview_img_links.append(row.preview_img_link)\n",
    "        preview_img_locals.append(row.preview_img_local)\n",
    "        img_url['preview_img_link'] = prview_img_links\n",
    "        img_url['preview_img_local'] = preview_img_locals\n",
    "        if not preview_imgs_urls.get(row.orig_id):\n",
    "            preview_imgs_urls[row.orig_id] = img_url\n",
    "\n",
    "    return preview_imgs_urls\n",
    "\n",
    "\n",
    "def grap_content_imgs_urls(table, engine):\n",
    "    '''\n",
    "    get img - url pair from the model\n",
    "    db_img_http: column name from the model,such as preview_img_link/title_img_url\n",
    "    db_img_local:column name from the mode, such as preview_img_local/title_img_local\n",
    "    '''\n",
    "    ori_df = pd.read_sql_table(table, engine)\n",
    "    content_imgs_urls = {}\n",
    "    for row in ori_df.itertuples():\n",
    "        #         print(dir(row))\n",
    "        img_url = {}\n",
    "        img_url['title_img_url'] = row.title_img_url\n",
    "        img_url['title_img_local'] = row.title_img_local\n",
    "        if not content_imgs_urls.get(row.orig_id):\n",
    "            content_imgs_urls[row.orig_id] = img_url\n",
    "\n",
    "    return content_imgs_urls\n",
    "\n",
    "\n",
    "def get_content_imgs_url(table, engine, content_imgs_urls):\n",
    "    ''' get imgs set from new content title\n",
    "    '''\n",
    "    not_down_content = {}\n",
    "    ori_df = pd.read_sql_table(table, engine, columns=['id', 'title', 'new_content'])\n",
    "    ori_df_imgs = ori_df['new_content'].apply(lambda x: BeautifulSoup(x).find_all('img'))\n",
    "    for _id, title, imgs in zip(ori_df['id'].values, ori_df['title'].values, ori_df_imgs.values):\n",
    "        #     print(_id,title,img,type(title),type(img))\n",
    "        img_value = {}\n",
    "        #         title_img_urls = []\n",
    "        content_img_urls = []\n",
    "        for img in imgs:\n",
    "            if isinstance(img, Tag):\n",
    "                content_img_url = img.attrs.get('src')\n",
    "                if re.match(r'http', content_img_url):\n",
    "                    #             print(title_img_url)\n",
    "                    content_img_urls.append(content_img_url)\n",
    "                    if not content_imgs_urls.get(str(_id) + str(title)):\n",
    "                        img_value['title_img_url'] = content_img_urls\n",
    "                        not_down_content[str(_id) + str(title)] = img_value\n",
    "\n",
    "    return not_down_content\n",
    "\n",
    "\n",
    "def get_preview_imgs_url(table, engine, preview_imgs_urls):\n",
    "    ''' get imgs set from preview img links\n",
    "    '''\n",
    "\n",
    "    not_down_previews = {}\n",
    "    ori_df = pd.read_sql_table(table, engine, columns=['id', 'title', 'preview_img_link'])\n",
    "    ori_df_imgs = ori_df['preview_img_link']\n",
    "    for _id, title, img in zip(ori_df['id'].values, ori_df['title'].values, ori_df_imgs.values):\n",
    "        #     print(_id,title,img,type(title),type(img))\n",
    "#         print(imgs)\n",
    "        img_value = {}\n",
    "        preview_img_urls = []\n",
    "#         for img in imgs:\n",
    "#             if re.match(r'http', img):\n",
    "#                 #             print(title_img_url)\n",
    "        preview_img_urls.append(img)\n",
    "        if not preview_imgs_urls.get(str(_id) + str(title)):\n",
    "            img_value['preview_img_link'] = preview_img_urls\n",
    "            not_down_previews[str(_id) + str(title)] = img_value\n",
    "    return not_down_previews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_imgs_urls = get_preview_imgs_url('news_oil_oe_pro', engine,{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_imgs(img_urls,img_url_key,img_url_local_key):\n",
    "    '''download imgs\n",
    "        img_url_key:'preview_img_link'\n",
    "        img_url_local_key:'preview_img_local'\n",
    "    '''\n",
    "    \n",
    "    imgs_downloaded = {}\n",
    "    imgs_not_downloaded = {}\n",
    "    \n",
    "    for ks,vs in img_urls.items():\n",
    "        \n",
    "        for img_key,img_links in vs.items(): #for each item inside \n",
    "            for img_link in img_links:\n",
    "#                 print(img_link)\n",
    "                if img_link: ##if there is link from img element\n",
    "                    img_file = os.path.join(save_dir,img_link.split('/')[-1])\n",
    "                    if  not os.path.exists(img_file): #check file already downloaded\n",
    "                        try: ## try to download the img file and save it\n",
    "                            res = req.get(url=img_link,\n",
    "                                          stream=True,\n",
    "                                         headers ={'user-agent':user_agent})\n",
    "                            with open(img_file,'wb') as f:\n",
    "                                f.write(res.content)\n",
    "                            imgs_downloaded[ks] = {img_url_key:img_link,\n",
    "                                                  img_url_local_key:img_file}\n",
    "#                             print('finish downloading')\n",
    "                        except: ## couldn't downloaded it\n",
    "                            continue\n",
    "                            \n",
    "                            imgs_not_downloaded[ks] = {img_url_key:img_link} #save the undownloaded img link\n",
    "                else: ## if img is None,save to avoid searching again\n",
    "                    imgs_not_downloaded[ks] = {img_url_key:None}\n",
    "                    \n",
    "    return imgs_downloaded,imgs_not_downloaded\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name_pro = ['news_oil_oe_pro','world_oil_pro','hart_energy_pro','cnpc_news_pro','oilfield_tech_pro',\\\n",
    "            'oil_and_gas_pro','in_en_storage_pro','jpt_latest_pro','energy_voice_pro','gulf_oil_gas_pro',\\\n",
    "            'energy_pedia_pro','up_stream_pro','oil_price_pro','inen_tech_pro','inen_newenergy_pro',\\\n",
    "            'drill_contractor_pro','rog_tech_pro','natural_gas_pro','rig_zone_pro','offshore_tech_pro',\n",
    "                  'jwn_energy_pro',\n",
    "            'energy_year_pro','energy_china_pro','china_five_pro','offshore_energy_pro','iran_oilgas_pro']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img={'4179New Well Testing Technology': {'preview_img_link': ['https://images.oedigital.com/images/maritime/w200h200/photo-schlumberger-93258.jpg']}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://images.oedigital.com/images/maritime/w200h200/photo-schlumberger-93258.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({}, {})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_imgs(test_img,'preview_img_link','preview_img_local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    uri = 'mysql+pymysql://root:jinzheng1706@139.198.191.224:3308/news_oil'\n",
    "    engine = db_connect(uri)\n",
    "    create_table(engine)\n",
    "    save_dir = '/Users/root1/mnt/img_dir'\n",
    "    \n",
    "    img_table='imgs_location'\n",
    "    content_urls_con = [] #list for saving all the table procssed content img\n",
    "    content_urls_not_con = []\n",
    "    preview_urls_con = [] # list for preview img url to \n",
    "    preview_urls_not_con = []\n",
    "    preview_imgs_urls = grap_preview_imgs_urls(img_table, engine) #noprocessed preview urls\n",
    "    content_imgs_urls = grap_content_imgs_urls(img_table, engine) #nonprocessed content url\n",
    "    for table in table_name_pro:\n",
    "        ua = UserAgent()\n",
    "        user_agent = ua.ie\n",
    "        not_down_preview = get_preview_imgs_url(table, engine, preview_imgs_urls)\n",
    "        imgs_downloaded,imgs_not_downloaded = download_imgs(not_down_preview,'preview_img_link','preview_img_local')\n",
    "        preview_urls_con.append(imgs_downloaded)\n",
    "        preview_urls_not_con.append(imgs_not_downloaded)\n",
    "        \n",
    "        break\n",
    "        \n",
    "        \n",
    "        \n",
    "#     grap_preview_imgs_urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= os.path.join('1','2','3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
